<html>
<head><meta charset="utf-8" /></head>
<body>
<div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script>
    <script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
</script>
<script src="https://cdn.plot.ly/plotly-2.3.0.min.js"></script>

    <div
        id=1b6c9058-d062-418a-bee2-465c64641ed3
        class="plotly-graph-div"
        style="height:500; width:700;">
    </div>
    <script type="text/javascript">
        
        window.PLOTLYENV = window.PLOTLYENV || {}
        
        if (document.getElementById('1b6c9058-d062-418a-bee2-465c64641ed3')) {
    Plotly.newPlot(
        '1b6c9058-d062-418a-bee2-465c64641ed3',
        [{"mode":"markers","y":[1.5606695,1.561543,1.5615939,1.5618728,1.5611167,1.5606334,1.5604513,1.562161,1.5618706,1.5614645,1.5625937,1.5621691,1.5619344,1.5615746,1.562607,1.5608051,1.5607675,1.5611198,1.5607461,1.560677,1.5613842,1.5610206,1.5613911,1.561361,1.561402,1.5614374,1.5613608,1.5616027,1.5617707,1.5614225,1.5615617,1.5615615,1.5615615,1.5615622,1.5615612,1.5615617,1.561562],"type":"scatter","name":"ideal","hovertemplate":"ideal reward = %{y:.3g}<extra></extra>","x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5,0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0,0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"line":{"color":"#1170AA"},"y":[1.1664299,1.2554182,1.3213459,1.3447006,1.3031077,1.1308686,0.76117474],"type":"scatter","name":"$\\epsilon\\text{-greedy }$","legendgroup":"#1170AA","hovertemplate":["ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.69530356","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.892764","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.0568082","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1734712","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1913009","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.9886718","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.5035745"],"x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5]},{"showlegend":false,"line":{"color":"#1170AA","dash":"dot","width":5},"y":[0.69530356,0.892764,1.0568082,1.1734712,1.1913009,0.9886718,0.5035745],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#1170AA","hovertemplate":["ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.69530356","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.892764","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.0568082","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1734712","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 1.1913009","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.9886718","ϵ = %{x:.2g}, reward = %{y:.3g} <extra> ϵ-greedy</extra>, reward 1 std worse = 0.5035745"],"x":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5]},{"line":{"color":"#FC7D0B"},"y":[1.123103,1.310423,1.4033457,1.4319413,1.3786062,1.2487545,1.0575933,0.78726363],"type":"scatter","name":"$\\text{gradient bandit }$","legendgroup":"#FC7D0B","hovertemplate":["α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.043819","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2329648","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.3008742","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2779498","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0910662","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.8092382","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.45116216","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.0024622679"],"x":[0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"showlegend":false,"line":{"color":"#FC7D0B","dash":"dot","width":5},"y":[1.043819,1.2329648,1.3008742,1.2779498,1.0910662,0.8092382,0.45116216,0.0024622679],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#FC7D0B","hovertemplate":["α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.043819","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2329648","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.3008742","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.2779498","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 1.0910662","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.8092382","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.45116216","α = %{x:.2g}, reward = %{y:.3g} <extra> gradient bandit</extra>, reward 1 std worse = 0.0024622679"],"x":[0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"line":{"color":"#A3ACB9"},"y":[1.4439069,1.4572772,1.4735943,1.5040092,1.5017374,1.4139333,1.1871663],"type":"scatter","name":"UCB","legendgroup":"#A3ACB9","hovertemplate":["c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2216178","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2601213","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.300394","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4003967","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4669158","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3798993","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.136002"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"showlegend":false,"line":{"color":"#A3ACB9","dash":"dot","width":5},"y":[1.2216178,1.2601213,1.300394,1.4003967,1.4669158,1.3798993,1.136002],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#A3ACB9","hovertemplate":["c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2216178","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.2601213","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.300394","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4003967","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.4669158","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.3798993","c = %{x:.2g}, reward = %{y:.3g} <extra> UCB</extra>, reward 1 std worse = 1.136002"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"line":{"color":"#57606C"},"y":[1.2485656,1.2797822,1.3318669,1.4163439,1.4765385,1.4367539,1.3500953,1.2582242],"type":"scatter","name":"$\\text{greedy optimistic initialization } \\alpha = 0.1$","legendgroup":"#57606C","hovertemplate":["Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8105159","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.86452734","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.9648427","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.1461971","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3567209","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3812224","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3103043","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.2158608"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0]},{"showlegend":false,"line":{"color":"#57606C","dash":"dot","width":5},"y":[0.8105159,0.86452734,0.9648427,1.1461971,1.3567209,1.3812224,1.3103043,1.2158608],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#57606C","hovertemplate":["Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.8105159","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.86452734","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 0.9648427","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.1461971","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3567209","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3812224","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.3103043","Q0 = %{x:.2g}, reward = %{y:.3g} <extra> greedy optimistic</extra>, reward 1 std worse = 1.2158608"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0]},{"line":{"color":"#5FA2CE"},"y":[1.5039145,1.5039147,1.5039145,1.503915,1.503914,1.5039141,1.5039133],"type":"scatter","name":"$\\text{Optimal Distribution}$","legendgroup":"#5FA2CE","hovertemplate":["Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406834","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406835","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406834","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406838","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.440682"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]},{"showlegend":false,"line":{"color":"#5FA2CE","dash":"dot","width":5},"y":[1.4406834,1.4406835,1.4406834,1.4406838,1.4406829,1.4406829,1.440682],"type":"scatter","name":"","legend":"legend2","opacity":0.25,"legendgroup":"#5FA2CE","hovertemplate":["Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406834","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406835","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406834","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406838","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.4406829","Minimum Variance = %{x:.2g}, reward = %{y:.3g} <extra> Optimal Distribution Sample</extra>, reward 1 std worse = 1.440682"],"x":[0.0625,0.125,0.25,0.5,1.0,2.0,4.0]}],
        {"xaxis":{"type":"log","tickvals":[0.0078125,0.015625,0.03125,0.0625,0.125,0.25,0.5,1.0,2.0,4.0,8.0],"title":"Method Parameter (see hovertext)","ticktext":["$\\frac{1}{128}$","$\\frac{1}{64}$","$\\frac{1}{32}$","$\\frac{1}{16}$","$\\frac{1}{8}$","$\\frac{1}{4}$","$\\frac{1}{2}$","$1$","$2$","$4$","$8$"]},"template":{"layout":{"coloraxis":{"colorbar":{"ticks":"","outlinewidth":0}},"xaxis":{"gridcolor":"white","zerolinewidth":2,"title":{"standoff":15},"ticks":"","zerolinecolor":"white","automargin":true,"linecolor":"white"},"hovermode":"closest","paper_bgcolor":"white","geo":{"showlakes":true,"showland":true,"landcolor":"#E5ECF6","bgcolor":"white","subunitcolor":"white","lakecolor":"white"},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"yaxis":{"gridcolor":"white","zerolinewidth":2,"title":{"standoff":15},"ticks":"","zerolinecolor":"white","automargin":true,"linecolor":"white"},"shapedefaults":{"line":{"color":"#2a3f5f"}},"hoverlabel":{"align":"left"},"mapbox":{"style":"light"},"polar":{"angularaxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","ticks":"","linecolor":"white"}},"autotypenumbers":"strict","font":{"color":"#2a3f5f"},"ternary":{"baxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","ticks":"","linecolor":"white"},"aaxis":{"gridcolor":"white","ticks":"","linecolor":"white"}},"annotationdefaults":{"arrowhead":0,"arrowwidth":1,"arrowcolor":"#2a3f5f"},"plot_bgcolor":"#E5ECF6","title":{"x":0.05},"scene":{"xaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"},"zaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"},"yaxis":{"gridcolor":"white","gridwidth":2,"backgroundcolor":"#E5ECF6","ticks":"","showbackground":true,"zerolinecolor":"white","linecolor":"white"}},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"]},"data":{"barpolar":[{"type":"barpolar","marker":{"line":{"color":"#E5ECF6","width":0.5}}}],"carpet":[{"aaxis":{"gridcolor":"white","endlinecolor":"#2a3f5f","minorgridcolor":"white","startlinecolor":"#2a3f5f","linecolor":"white"},"type":"carpet","baxis":{"gridcolor":"white","endlinecolor":"#2a3f5f","minorgridcolor":"white","startlinecolor":"#2a3f5f","linecolor":"white"}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"parcoords":[{"line":{"colorbar":{"ticks":"","outlinewidth":0}},"type":"parcoords"}],"scatter":[{"type":"scatter","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram2dcontour":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"histogram2dcontour","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contour":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"contour","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"mesh3d":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"mesh3d"}],"surface":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"surface","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram":[{"type":"histogram","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"pie":[{"type":"pie","automargin":true}],"choropleth":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"choropleth"}],"heatmapgl":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"heatmapgl","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"bar":[{"type":"bar","error_y":{"color":"#2a3f5f"},"error_x":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5}}}],"heatmap":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"heatmap","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"contourcarpet"}],"table":[{"type":"table","header":{"line":{"color":"white"},"fill":{"color":"#C8D4E3"}},"cells":{"line":{"color":"white"},"fill":{"color":"#EBF0F8"}}}],"scatter3d":[{"line":{"colorbar":{"ticks":"","outlinewidth":0}},"type":"scatter3d","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"histogram2d":[{"colorbar":{"ticks":"","outlinewidth":0},"type":"histogram2d","colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"ticks":"","outlinewidth":0}}}]}},"legend":{"y":-0.2,"orientation":"h","x":-0.1},"margin":{"l":50,"b":50,"r":50,"t":60},"yaxis":{"title":"Average Reward over first 1000 steps"},"height":500,"width":700},
        {"editable":false,"responsive":true,"staticPlot":false,"scrollZoom":true},
    )
}

        
    </script>
</div>

</body>
</html>